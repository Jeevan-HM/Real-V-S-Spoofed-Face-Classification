{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Import Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model, model_from_json\n",
    "from keras.preprocessing import image as img\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Cascading*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(\"haarcascades/haarcascade_frontalface_default.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier(\"haarcascades/haarcascade_eye.xml\")\n",
    "side_profile = cv2.CascadeClassifier(\"haarcascades/haarcascade_profileface.xml\")\n",
    "glass_cascade = cv2.CascadeClassifier(\"haarcascades/haarcascade_eye_tree_eyeglasses.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Brightness and Contrast (Alpha Beta) Correction *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightness_correction(image):\n",
    "    filtered_image = np.zeros(image.shape, image.dtype)\n",
    "    alpha = 1\n",
    "    beta = 50\n",
    "    for y in range(image.shape[0]):\n",
    "        for x in range(image.shape[1]):\n",
    "            for c in range(image.shape[2]):\n",
    "                filtered_image[y, x, c] = np.clip(alpha * image[y, x, c] + beta, 0, 255)\n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Gamma Correction*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_stretching(input, lower_stretch_from, upper_stretch_from):\n",
    "    lower_stretch_to = 0  \n",
    "    upper_stretch_to = 255\n",
    "    output = (input - lower_stretch_from) * ((upper_stretch_to - lower_stretch_to) / (upper_stretch_from - lower_stretch_from)) + lower_stretch_to\n",
    "    return output\n",
    "\n",
    "def gamma_correction(image):\n",
    "    gamma_image = image.copy()\n",
    "    max_value = np.max(gamma_image)\n",
    "    min_value = np.min(gamma_image)\n",
    "    for y in range(len(gamma_image)):\n",
    "        for x in range(len(gamma_image[y])):\n",
    "            gamma_image[y][x] = linear_stretching(gamma_image[y][x], min_value, max_value)\n",
    "    return gamma_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Fixing/Normalizing the images*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    image = image.copy()\n",
    "    output = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    dst = cv2.equalizeHist(output)\n",
    "    image = dst.copy()\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Function to detect Face and eyes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect face\n",
    "def detect_face(image):\n",
    "    try:\n",
    "        face_image = image.copy()\n",
    "        face_rect = face_cascade.detectMultiScale(face_image, scaleFactor=1.2, minNeighbors=5)\n",
    "        face_cords =[]\n",
    "        face_detection = 0\n",
    "        for (x, y, w, h) in face_rect:\n",
    "            cv2.rectangle(face_image, (x, y), (x + w, y + h), (255, 255, 255), 10)\n",
    "            roi=face_image[y:y+h,x:x+w]\n",
    "            face_image = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "            face_cords.append([x,y,w,h])\n",
    "            cv2.imwrite(\"extracted\" + '.png', roi)\n",
    "        if len(face_cords) >= 1:\n",
    "            face_detection = len(face_cords)\n",
    "            return {\"image\": face_image, \"detection\": face_detection, \"roi\": roi}\n",
    "            \n",
    "        else:\n",
    "            return {\"image\": face_image, \"detection\": face_detection}\n",
    "    except Exception as e:\n",
    "        return{\"image\": image, \"detection\": 0}\n",
    "\n",
    "# Function to detect eyes\n",
    "def detect_eyes(image):\n",
    "    try:\n",
    "        eye_image = image.copy()\n",
    "        eye_rect = eye_cascade.detectMultiScale(eye_image, scaleFactor=1.2, minNeighbors=5)\n",
    "        eye_cords = []\n",
    "        eye_detection = 0\n",
    "        for (x, y, w, h) in eye_rect:\n",
    "            if len(eye_rect) == 2:\n",
    "                cv2.rectangle(eye_image, (x, y), (x + w, y + h), (255, 255, 255), 10)\n",
    "                eye_cords.append([x,y,w,h])\n",
    "        if len(eye_cords) >= 1:\n",
    "            eye_detection = len(eye_cords)\n",
    "        return {\"image\": eye_image, \"detection\": eye_detection}\n",
    "    except Exception as e:\n",
    "        return{\"image\": image, \"detection\": 0}\n",
    "\n",
    "def detect_glass(image):\n",
    "    try:\n",
    "        glass_image = image.copy()\n",
    "        glass_rect = glass_cascade.detectMultiScale(glass_image, scaleFactor=1.2)\n",
    "        # print(\"Glass Detection = \" + str(len(glass_rect)))\n",
    "        return {\"image\": glass_image, \"detection\": len(glass_rect)}\n",
    "    except Exception as e:\n",
    "        return{\"image\": image, \"detection\": 0}\n",
    "\n",
    "def detect_profile(image):\n",
    "    try:\n",
    "        profile_image = image.copy()\n",
    "        profile_rect = side_profile.detectMultiScale(profile_image, scaleFactor=1.2)\n",
    "        # print(\"Profile Detection = \" + str(len(profile_rect)))\n",
    "        return {\"image\": glass_image, \"detection\": len(glass_rect)}\n",
    "    except Exception as e:\n",
    "        return{\"image\": image, \"detection\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *CNN Network*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    try:\n",
    "        json_file = open(\"models/model.json\", \"r\")\n",
    "        loaded_model = json_file.read()\n",
    "        json_file.close()\n",
    "\n",
    "        load_model = model_from_json(loaded_model)\n",
    "        load_model.load_weights(\"models/model.h5\")\n",
    "\n",
    "        test_image = img.load_img('extracted.png', target_size=(200, 200, 3))\n",
    "        test_image = img.img_to_array(test_image)\n",
    "        test_image = np.expand_dims(test_image, axis=0)\n",
    "        result = load_model.predict(test_image)\n",
    "        if result[0][0] == 1:\n",
    "            return {\"message\": \"Real Face\"}\n",
    "        else:\n",
    "            return {\"message\":\"Fake Face\"}\n",
    "    except Exception as e:\n",
    "        return {\"message\":e}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *SSD Detection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd(image):\n",
    "    try:\n",
    "        id = 0\n",
    "        className = [\"person\"]\n",
    "        classFile = \"config/coco.names\"\n",
    "        configPath = \"config/ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt\"\n",
    "        weightsPath = \"config/frozen_inference_graph.pb\"\n",
    "        net = cv2.dnn_DetectionModel(weightsPath, configPath)\n",
    "        net.setInputSize(200, 200)\n",
    "        net.setInputScale(1.0 / 127.5)\n",
    "        net.setInputMean((127.5, 127.5, 127.5))\n",
    "        net.setInputSwapRB(True)\n",
    "        classIDs, confs, bbox = net.detect(image)\n",
    "        id = len(classIDs)\n",
    "        return {\"detection\": id}\n",
    "    except Exception as e:\n",
    "        return {\"detection\": e}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(image):\n",
    "    try:\n",
    "        original_height, original_width = image.shape[:2]\n",
    "        image_resize = cv2.resize(image, (200, 200), interpolation=cv2.INTER_AREA)\n",
    "        brightness_corrected = brightness_correction(image_resize)\n",
    "        filtered_image = gamma_correction(brightness_corrected)\n",
    "        filtered_image = cv2.cvtColor(filtered_image, cv2.COLOR_BGR2GRAY)\n",
    "        normalized_image = normalize_image(filtered_image)\n",
    "        image_resize = cv2.resize(normalized_image, (original_width, original_height), interpolation=cv2.INTER_LANCZOS4)\n",
    "        glass_detction = detect_glass(image_resize)\n",
    "        profile_detection = detect_profile(image_resize)\n",
    "        face = detect_face(image_resize)\n",
    "        original_eye = detect_eyes(image)\n",
    "        filtered_eye = detect_eyes(image_resize)\n",
    "        # print(\"Face \" + str(face[\"detection\"]))\n",
    "        # print(\"Filtered eye \" + str(filtered_eye[\"detection\"]))\n",
    "        # print(\"original_eye \" + str(original_eye[\"detection\"]))\n",
    "        if face[\"detection\"] >= 1 and filtered_eye[\"detection\"] == 2:\n",
    "            return {\"message\": \"Real Face\"}\n",
    "        elif face[\"detection\"] == 1 and filtered_eye[\"detection\"] >=0 and original_eye[\"detection\"] > 0:\n",
    "            return {\"message\": cnn_model()[\"message\"]}\n",
    "        elif filtered_eye[\"detection\"] > 0 and original_eye[\"detection\"] == 2:\n",
    "            return {\"message\": cnn_model()[\"message\"]}\n",
    "        elif filtered_eye[\"detection\"] == 2:\n",
    "            return {\"message\": cnn_model()[\"message\"]}\n",
    "        elif profile_detection[\"detection\"] > 0 or (glass_detction[\"detection\"] > 0 and glass_detction[\"detection\"] < 3 and face[\"detection\"] >= 1):\n",
    "            return {\"message\": cnn_model()[\"message\"]}\n",
    "        else:\n",
    "            return {\"message\":\"Fake Face\"}\n",
    "    except Exception as e:\n",
    "        return {\"message\":e}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Classify real vs Fake image*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"input/glasses\"\n",
    "# i = 1\n",
    "# for image_path in os.listdir(path):\n",
    "#     input_path = os.path.join(path, image_path)\n",
    "#     input_image = cv2.imread(input_path)\n",
    "#     detection = ssd(input_image)[\"detection\"]\n",
    "#     # print(\"Detection = \" + str(detection))\n",
    "#     if detection < 3:\n",
    "#         # print(str(i) +\" : \"+ str(image_path))     \n",
    "#         message = classification(input_image)[\"message\"]\n",
    "#         print(str(i) + \"::File - \" + str(image_path) + \", Message - \" + str(message))\n",
    "#     else:   \n",
    "#         print(str(i) + \"::File - \" + str(image_path) + \", Message - Fake Face\")\n",
    "#     i += 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"input/Fake_Faces\"\n",
    "# i = 1\n",
    "# for image_path in os.listdir(path):\n",
    "#     input_path = os.path.join(path, image_path)\n",
    "#     input_image = cv2.imread(input_path)\n",
    "#     detection = ssd(input_image)[\"detection\"]\n",
    "#     # print(\"Detection = \" + str(detection))\n",
    "#     if detection < 3:\n",
    "#         # print(str(i) +\" : \"+ str(image_path))     \n",
    "#         message = classification(input_image)[\"message\"]\n",
    "#         print(str(i) + \"::File - \" + str(image_path) + \", Message - \" + str(message))\n",
    "#     else:\n",
    "#         print(str(i) + \"::File - \" + str(image_path) + \", Message - Fake Face\")\n",
    "#     i += 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"input/Real_Faces\"\n",
    "# i = 1\n",
    "# for image_path in os.listdir(path):\n",
    "#     input_path = os.path.join(path, image_path)\n",
    "#     input_image = cv2.imread(input_path)\n",
    "#     detection = ssd(input_image)[\"detection\"]\n",
    "#     if detection < 3:\n",
    "#         message = classification(input_image)[\"message\"]     \n",
    "#         print(str(i) + \"::File - \" + str(image_path) + \", Message - \" + str(message))\n",
    "#     else:\n",
    "#         print(str(i) + \"::File - \" + str(image_path) + \", Message - Fake Face\")\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Message - Real Face\n"
     ]
    }
   ],
   "source": [
    "input_image = cv2.imread(\"input/2020-12-11-203654.jpg\")\n",
    "detection = ssd(input_image)[\"detection\"]\n",
    "if detection < 3:\n",
    "    message = classification(input_image)[\"message\"]\n",
    "    print(\"Message - \" + str(message))\n",
    "else:\n",
    "    print(\"Message - Fake Face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "ai",
   "display_name": "ai",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}